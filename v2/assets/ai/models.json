[
  {
    "label_part1": "Source",
    "label_part2": "AI",
    "value": "free::sourceai",
    "description": "Free & Great for everyday task üê±‚Äçüèç"
  },
  {
    "label_part1": "Deminji-1.5",
    "label_part2": "Bylearn",
    "value": "bytarch::deminji-scorpio",
    "description": "Deminji 1.5 Scorpio - The most powerful model for complex computations."
  },
  {
    "label_part1": "ChatGPT",
    "label_part2": "Pro",
    "value": "501::chatgpt-pro",
    "description": "ChatGPT Pro"
  },
  {
    "label_part1": "Son",
    "label_part2": "r1",
    "value": "net::pro-r1",
    "description": "An Advance Reasoning Model"
  },
  {
    "label_part1": "DeepSeek",
    "label_part2": "v3",
    "value": "501::deepseek-v3",
    "description": "The best Open Source Model yet"
  },
  {
    "label_part1": "Flux",
    "label_part2": "",
    "value": "502::flux",
    "description": "Image Generation"
  },
  {
    "label_part1": "Claude",
    "label_part2": "3 Haiku",
    "value": "nxus::claude-3-haiku-20240307",
    "description": "The fastest of the three Claude 3 models"
  },
  {
    "label_part1": "Nemotron3.1",
    "label_part2": "70B",
    "value": "beta::nvidia/Llama-3.1-Nemotron-70B-Instruct",
    "description": "Nvidia Latest Model"
  },
  {
    "label_part1": "Mixtral",
    "label_part2": "8x",
    "value": "nxus::mistralai/Mixtral-8x7B-Instruct-v0.1",
    "description": "The base model optimized for chat purposes"
  },
  {
    "label_part1": "ChatGPT",
    "label_part2": "3.5 Turbo",
    "value": "lxus::gpt-3.5-turbo",
    "description": "ChatGPT 3.5 - OpenAI GPT 3.5 Turbo Model"
  },
  {
    "label_part1": "Llama",
    "label_part2": "3.3",
    "value": "beta::meta-llama/Llama-3.3-70B-Instruct",
    "description": "Meta's Model"
  },
  {
    "label_part1": "Marco-o1",
    "label_part2": "",
    "value": "22::marco-o1",
    "description": ""
  },
  {
    "label_part1": "Sonar Reasoning",
    "label_part2": "",
    "value": "22::sonar-reasoning",
    "description": ""
  },
  {
    "label_part1": "o3-mini",
    "label_part2": "",
    "value": "22::o3-mini-low",
    "description": ""
  },
  {
    "label_part1": "DeepSeek-R1-Distill-Llama-70B",
    "label_part2": "",
    "value": "beta::deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
    "description": ""
  },
  {
    "label_part1": "",
    "label_part2": "",
    "value": "beta::deepseek-ai/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "description": ""
  },
  {
    "label_part1": "",
    "label_part2": "",
    "value": "beta::deepseek-ai/DeepSeek-V3",
    "description": ""
  },
  {
    "label_part1": "",
    "label_part2": "",
    "value": "beta::deepseek-ai/DeepSeek-R1",
    "description": ""
  },
  {
    "label_part1": "mistralai",
    "label_part2": "Mixtral-8x22B-Instruct-v0.1",
    "value": "beta::mistralai/Mixtral-8x22B-Instruct-v0.1",
    "description": ""
  },
  {
    "label_part1": "mistralai",
    "label_part2": "Mistral-7B-Instruct-v0.3",
    "value": "beta::mistralai/Mistral-7B-Instruct-v0.3",
    "description": ""
  },
  {
    "label_part1": "Qwen",
    "label_part2": "Qwen2.5-72B-Instruct",
    "value": "beta::Qwen/Qwen2.5-72B-Instruct",
    "description": ""
  },
  {
    "label_part1": "meta-llama",
    "label_part2": "Meta-Llama-3-8B-Instruct",
    "value": "beta::meta-llama/Meta-Llama-3-8B-Instruct",
    "description": ""
  },
  {
    "label_part1": "meta-llama",
    "label_part2": "Meta-Llama-3-70B-Instruct",
    "value": "beta::meta-llama/Meta-Llama-3-70B-Instruct",
    "description": ""
  },
  {
    "label_part1": "meta-llama",
    "label_part2": "Meta-Llama-3.1-405B-Instruct",
    "value": "beta::meta-llama/Meta-Llama-3.1-405B-Instruct",
    "description": ""
  },
  {
    "label_part1": "meta-llama",
    "label_part2": "Meta-Llama-3.1-70B-Instruct",
    "value": "beta::meta-llama/Meta-Llama-3.1-70B-Instruct",
    "description": ""
  },
  {
    "label_part1": "meta-llama",
    "label_part2": "Meta-Llama-3.1-8B-Instruct",
    "value": "beta::meta-llama/Meta-Llama-3.1-8B-Instruct",
    "description": ""
  },
  {
    "label_part1": "meta-llama",
    "label_part2": "Meta-Llama-3.1-70B-Instruct-Turbo",
    "value": "beta::meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
    "description": ""
  },
  {
    "label_part1": "meta-llama",
    "label_part2": "Llama-3.3-70B-Instruct",
    "value": "beta::meta-llama/Llama-3.3-70B-Instruct",
    "description": ""
  },
  {
    "label_part1": "meta-llama",
    "label_part2": "Llama-3.3-70B-Instruct-Turbo",
    "value": "beta::meta-llama/Llama-3.3-70B-Instruct-Turbo",
    "description": ""
  },
  {
    "label_part1": "nvidia",
    "label_part2": "Llama-3.1-Nemotron-70B-Instruct",
    "value": "beta::nvidia/Llama-3.1-Nemotron-70B-Instruct",
    "description": ""
  },
  {
    "label_part1": "microsoft",
    "label_part2": "phi-4",
    "value": "beta::microsoft/phi-4",
    "description": ""
  },
  {
    "label_part1": "mistralai",
    "label_part2": "Mistral-Small-24B-Instruct-2501",
    "value": "beta::mistralai/Mistral-Small-24B-Instruct-2501",
    "description": ""
  },
  {
    "label_part1": "qwen",
    "label_part2": "qwen-32b-preview",
    "value": "11::qwen-32b-preview",
    "description": ""
  },
  {
    "label_part1": "meta-llama",
    "label_part2": "Llama-3.2-90B-Vision-Instruct",
    "value": "beta::meta-llama/Llama-3.2-90B-Vision-Instruct",
    "description": ""
  },
  {
    "label_part1": "meta-llama",
    "label_part2": "Llama-3.2-11B-Vision-Instruct",
    "value": "beta::meta-llama/Llama-3.2-11B-Vision-Instruct",
    "description": ""
  },
  {
    "label_part1": "",
    "label_part2": "",
    "value": "02::llama",
    "description": ""
  },  
  {
    "label_part1": "research",
    "label_part2": "research",
    "value": "research::research",
    "description": ""
  },
  {
    "label_part1": "tutor",
    "label_part2": "tutor",
    "value": "tutor::tutor",
    "description": ""
  }
  

]
